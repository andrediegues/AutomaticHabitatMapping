{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from shutil import copyfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDirectoryEnvironment(train_data, train_targets, val_data, val_targets, path):\n",
    "    trainpath = path + 'train/'\n",
    "    valpath = path + 'validation/'\n",
    "    if(os.listdir() == 2):\n",
    "        return trainpath,valpath\n",
    "    if(not os.path.exists(trainpath)):\n",
    "        os.mkdir(trainpath)\n",
    "    if(not os.path.exists(valpath)):\n",
    "        os.mkdir(valpath)\n",
    "        \n",
    "    classes = train_targets.columns.append(val_targets.columns).drop_duplicates()  \n",
    "    for c in classes:\n",
    "        train_class = trainpath + c + '/'\n",
    "        val_class = valpath + c + '/'\n",
    "        if(not os.path.exists(train_class)):\n",
    "            os.mkdir(train_class)\n",
    "        if(not os.path.exists(val_class)):\n",
    "            os.mkdir(val_class)\n",
    "            \n",
    "    for f in train_data.index.values:\n",
    "        copyfile(path + '../CV/' + f[:f.find('frame')-1] + '/icm/' + f, trainpath + train_targets.loc[f].idxmax(axis = 1) + '/' + f)\n",
    "    for f in val_data.index.values:\n",
    "        copyfile(path + '../CV/' + f[:f.find('frame')-1] + '/icm/' + f, valpath + val_targets.loc[f].idxmax(axis = 1) + '/' + f)\n",
    "    \n",
    "    return trainpath, valpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/diegues/Desktop/ProcessedImages/\"\n",
    "data = pd.read_csv(folder_path + \"sampled_data.csv\")\n",
    "\n",
    "filenames = data['filename']\n",
    "targets = data['level3']\n",
    "\n",
    "# one-hot encoding\n",
    "targets_ohe = pd.get_dummies(targets)\n",
    "\n",
    "# dealing with NaNs\n",
    "data = data.drop(['roll', 'pitch', 'level1', 'level2', 'level3', 'level4', \n",
    "                  'level5', 'level6', 'AphiaID', 'EunisName', 'EunisCode', \n",
    "                  'date', 'timestamp', 'species'],\n",
    "                 axis = 1)\n",
    "\n",
    "X = data.groupby('filename').max()\n",
    "Y = pd.concat([filenames,targets_ohe], axis = 1).groupby('filename').max()\n",
    "\n",
    "\n",
    "# tts\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size = 0.3, random_state=47)\n",
    "\n",
    "images_path = '/home/diegues/Desktop/ProcessedImages/SampledData/'\n",
    "train_dir, val_dir = createDirectoryEnvironment(train_X, train_Y, test_X, test_Y, images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 344, 344, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 344, 344, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 344, 344, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 172, 172, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 172, 172, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 172, 172, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 86, 86, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 86, 86, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 86, 86, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 86, 86, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 43, 43, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 43, 43, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 43, 43, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 43, 43, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 21, 21, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 21, 21, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 21, 21, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 21, 21, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 10, 10, 512)       0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_ft = VGG16(weights = 'imagenet', include_top=False, input_shape=(344, 344, 3))\n",
    "vgg16_ft.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 10, 10, 512)       14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              52429824  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 69,250,887\n",
      "Trainable params: 69,250,887\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "eunis_classifier = Sequential()\n",
    "eunis_classifier.add(vgg16_ft)\n",
    "eunis_classifier.add(Flatten())\n",
    "eunis_classifier.add(Dense(1024, activation='relu'))\n",
    "eunis_classifier.add(Dropout(0.5))\n",
    "eunis_classifier.add(Dense(1024, activation='relu'))\n",
    "eunis_classifier.add(Dropout(0.5))\n",
    "eunis_classifier.add(Dense(1024, activation='relu'))\n",
    "eunis_classifier.add(Dropout(0.5))\n",
    "eunis_classifier.add(Dense(7, activation='softmax'))\n",
    "\n",
    "eunis_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eunis_classifier.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x7fa38cb8fa90> False\n",
      "<keras.layers.core.Flatten object at 0x7fa38c572fd0> True\n",
      "<keras.layers.core.Dense object at 0x7fa38c574048> True\n",
      "<keras.layers.core.Dropout object at 0x7fa38c5b54a8> True\n",
      "<keras.layers.core.Dense object at 0x7fa38c60c1d0> True\n",
      "<keras.layers.core.Dropout object at 0x7fa38c60c438> True\n",
      "<keras.layers.core.Dense object at 0x7fa38cae4d30> True\n",
      "<keras.layers.core.Dropout object at 0x7fa38c5ded68> True\n",
      "<keras.layers.core.Dense object at 0x7fa38caaec18> True\n"
     ]
    }
   ],
   "source": [
    "for layer in eunis_classifier.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4181a4a2c15a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m train_generator = train_datagen.flow_from_directory(\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m344\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m344\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_batchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dir' is not defined"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "train_batchsize = 4\n",
    "val_batchsize = 4\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(344, 344),\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(344, 344),\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_optimizer = SGD(lr=0.01, decay=0.5)\n",
    "eunis_classifier.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=sgd_optimizer, \n",
    "                        metrics=['acc'])\n",
    "tensorboard = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "best_checkpoint = ModelCheckpoint('./weights/FT-VGG16-Best.h5', save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_delta=1e-5, min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = eunis_classifier.fit_generator(train_generator, \n",
    "                                         steps_per_epoch=len(train_X)//train_batchsize,\n",
    "                                         epochs=100,\n",
    "                                         validation_data=validation_generator,\n",
    "                                         validation_steps = len(test_X)//val_batchsize,\n",
    "                                         callbacks=[tensorboard, best_checkpoint, earlystop, reducer]\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(len(acc))\n",
    " \n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    " \n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
