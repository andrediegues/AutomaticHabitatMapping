{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diegues/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from shutil import copyfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import SVG,display\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Tuning\n",
    "    - Try different LR (starting from 1.0 to 0.001) and see differences (no. of epochs, resulting accuracies and performance)\n",
    "    - Compare with using Adam and Nesterov Momentum SGD\n",
    "    - Try out different CNNs designs (DenseNet, ResNet50, Inception v3)\n",
    "    - Compare performances and scores (no.epochs, accuracies, etc)\n",
    "    - Add more samples\n",
    "    - Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        timestamp  latitude  longitude   roll  \\\n",
      "filename                                                                        \n",
      "113610_cam_survey_1_frame1246.jpg    1.525175e+09  41.53323   -8.81036  -3.11   \n",
      "113610_cam_survey_1_frame1272.jpg    1.525175e+09  41.53324   -8.81036  -0.24   \n",
      "132143_forcadinho-np3_frame1317.jpg  1.525183e+09  41.53305   -8.80962  -3.47   \n",
      "113610_cam_survey_1_frame2894.jpg    1.525176e+09  41.53307   -8.80638   0.87   \n",
      "113610_cam_survey_1_frame2643.jpg    1.525176e+09  41.53337   -8.80586 -23.16   \n",
      "\n",
      "                                     pitch    entropy      date  depth  \\\n",
      "filename                                                                 \n",
      "113610_cam_survey_1_frame1246.jpg   -20.12  21.806570  01/05/18   9.67   \n",
      "113610_cam_survey_1_frame1272.jpg   -21.64  21.847648  01/05/18   8.34   \n",
      "132143_forcadinho-np3_frame1317.jpg -22.16  21.671617  01/05/18   9.81   \n",
      "113610_cam_survey_1_frame2894.jpg   -17.67  21.931659  01/05/18   8.83   \n",
      "113610_cam_survey_1_frame2643.jpg   -19.00  21.929502  01/05/18   9.28   \n",
      "\n",
      "                                    EunisCode  \\\n",
      "filename                                        \n",
      "113610_cam_survey_1_frame1246.jpg        A3.1   \n",
      "113610_cam_survey_1_frame1272.jpg        A3.1   \n",
      "132143_forcadinho-np3_frame1317.jpg      A3.1   \n",
      "113610_cam_survey_1_frame2894.jpg       A3.11   \n",
      "113610_cam_survey_1_frame2643.jpg       A3.11   \n",
      "\n",
      "                                                                             EunisName  \\\n",
      "filename                                                                                 \n",
      "113610_cam_survey_1_frame1246.jpg    Atlantic and Mediterranean high energy infrali...   \n",
      "113610_cam_survey_1_frame1272.jpg    Atlantic and Mediterranean high energy infrali...   \n",
      "132143_forcadinho-np3_frame1317.jpg  Atlantic and Mediterranean high energy infrali...   \n",
      "113610_cam_survey_1_frame2894.jpg    Kelp with cushion fauna and/or foliose red sea...   \n",
      "113610_cam_survey_1_frame2643.jpg    Kelp with cushion fauna and/or foliose red sea...   \n",
      "\n",
      "                                    level1 level2 level3 level4 level5  \\\n",
      "filename                                                                 \n",
      "113610_cam_survey_1_frame1246.jpg        A     A3   A3.1    NaN    NaN   \n",
      "113610_cam_survey_1_frame1272.jpg        A     A3   A3.1    NaN    NaN   \n",
      "132143_forcadinho-np3_frame1317.jpg      A     A3   A3.1    NaN    NaN   \n",
      "113610_cam_survey_1_frame2894.jpg        A     A3   A3.1  A3.11    NaN   \n",
      "113610_cam_survey_1_frame2643.jpg        A     A3   A3.1  A3.11    NaN   \n",
      "\n",
      "                                     level6                  species   AphiaID  \n",
      "filename                                                                        \n",
      "113610_cam_survey_1_frame1246.jpg       NaN            Paracentrotus       NaN  \n",
      "113610_cam_survey_1_frame1272.jpg       NaN                      NaN       NaN  \n",
      "132143_forcadinho-np3_frame1317.jpg     NaN  Marthasterias glacialis  123803.0  \n",
      "113610_cam_survey_1_frame2894.jpg       NaN                      NaN       NaN  \n",
      "113610_cam_survey_1_frame2643.jpg       NaN                      NaN       NaN  \n",
      "                                  date  longitude  latitude  depth EunisCode  \\\n",
      "filename                                                                       \n",
      "105317_cam-np3_frame1347.jpg  01/05/18   -8.81545  41.53153  17.61      A3.7   \n",
      "105317_cam-np3_frame1352.jpg  01/05/18   -8.81545  41.53153  17.61      A3.7   \n",
      "105317_cam-np3_frame1390.jpg  01/05/18   -8.81299  41.53317   6.06      A3.1   \n",
      "105317_cam-np3_frame1468.jpg  01/05/18   -8.81573  41.53185  15.50      A4.1   \n",
      "105317_cam-np3_frame1473.jpg  01/05/18   -8.81139  41.53005  18.55      A4.1   \n",
      "\n",
      "                                                                      EunisName  \\\n",
      "filename                                                                          \n",
      "105317_cam-np3_frame1347.jpg                                                NaN   \n",
      "105317_cam-np3_frame1352.jpg                                                NaN   \n",
      "105317_cam-np3_frame1390.jpg  Atlantic and Mediterranean high energy infrali...   \n",
      "105317_cam-np3_frame1468.jpg  Atlantic and Mediterranean high energy circali...   \n",
      "105317_cam-np3_frame1473.jpg  Atlantic and Mediterranean high energy circali...   \n",
      "\n",
      "                             level1 level2 level3  level4  level5  level6  \\\n",
      "filename                                                                    \n",
      "105317_cam-np3_frame1347.jpg      A     A3   A3.7     NaN     NaN     NaN   \n",
      "105317_cam-np3_frame1352.jpg      A     A3   A3.7     NaN     NaN     NaN   \n",
      "105317_cam-np3_frame1390.jpg      A     A3   A3.1     NaN     NaN     NaN   \n",
      "105317_cam-np3_frame1468.jpg      A     A4   A4.1     NaN     NaN     NaN   \n",
      "105317_cam-np3_frame1473.jpg      A     A4   A4.1     NaN     NaN     NaN   \n",
      "\n",
      "                              species  AphiaID  \n",
      "filename                                        \n",
      "105317_cam-np3_frame1347.jpg      NaN      NaN  \n",
      "105317_cam-np3_frame1352.jpg      NaN      NaN  \n",
      "105317_cam-np3_frame1390.jpg      NaN      NaN  \n",
      "105317_cam-np3_frame1468.jpg      NaN      NaN  \n",
      "105317_cam-np3_frame1473.jpg      NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "folder = '/media/newdrive/20180501/ProcessedImages/'\n",
    "train_path = folder + 'SampledData/train/'\n",
    "val_path = folder + 'SampledData/validation/'\n",
    "test_path = folder + 'test/'\n",
    "\n",
    "train_df = pd.read_csv(folder + 'sampled_data.csv').set_index('filename')\n",
    "test_df = pd.read_csv(folder + 'unknown2-targets.csv').set_index('filename')\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 457 images belonging to 5 classes.\n",
      "Found 197 images belonging to 5 classes.\n",
      "Found 751 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=360,\n",
    "      vertical_flip=True,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=1,\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=1,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=1,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CallBacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir='./Graph/vgg16_1', histogram_freq=0, write_graph=True, write_images=True)\n",
    "best_checkpoint = ModelCheckpoint('./weights/vgg16_1_cp.h5', monitor='val_acc', save_best_only=True, verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=10, verbose=1)\n",
    "reducer = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=3, verbose=1, min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers\n",
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd1 = SGD(lr=1)\n",
    "sgd0_1 = SGD(lr=.1)\n",
    "sgd0_01 = SGD(lr=.01)\n",
    "sgd0_001 = SGD(lr=.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(weights='imagenet')\n",
    "fc1 = vgg.layers[-3]\n",
    "fc2 = vgg.layers[-2]\n",
    "predictions = Dense(5, activation='softmax', name='predictions')\n",
    "\n",
    "\n",
    "dropout1 = Dropout(0.5)\n",
    "dropout2 = Dropout(0.5)\n",
    "\n",
    "x = dropout1(fc1.output)\n",
    "x = fc2(x)\n",
    "x = dropout2(x)\n",
    "predictors = predictions(x)\n",
    "\n",
    "eunis_classifier_w_dropout = Model(input=vgg.input, output=predictors)\n",
    "eunis_classifier_w_dropout.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=sgd1, \n",
    "                        metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_w_drop = eunis_classifier_w_dropout.fit_generator(train_generator, \n",
    "                                         steps_per_epoch=457,\n",
    "                                         epochs=500,\n",
    "                                         validation_data=validation_generator,\n",
    "                                         validation_steps = 197,\n",
    "                                         callbacks=[tensorboard, best_checkpoint, earlystop, reducer]\n",
    "                                        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
